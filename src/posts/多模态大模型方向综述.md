
精读(perhaps)了《A Survey on Multimodal Large Language Models》（IEEE2024）这篇文章有关MLLM的发展历程概括，论文中还给了一个github链接[https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models)，这篇论文不曾想，点进去就看到了南大的标，并且这篇论文很帅气地写下了这句话：

**"To the best of our knowledge, this is the first survey on MLLM."**

**"据我们所知，这篇综述是MLMM方向的第一篇综述"**

![](https://github.com/BradyFU/Awesome-Multimodal-Large-Language-Models/raw/main/images/MiG_logo.jpg)

原来是南大发的论文 出于好奇，我搜了一下Mig小组，发现该组有4位老师，其中两位老师恰好是我这个学期计算机系统基础的老师。

9月28日更正：这篇论文的作者来自南大，中科大和腾讯，其中南大的Fu Chaoyou是共一+project leader

---

## LLM，LVM，MLLM

LLM(Large Model) 参数量大，强于推理能力，但是没有视觉

LVM（Large Vision Model）能够理解图像，但是没有推理能力

MLLM（Multimodel Large Langage Model）继承了大参数的特点的同时，使用了新的训练范式。并且在应用场景和功能上进行了扩充：能够读懂多种模态的信息（model）

## MLLM Architecture

![](https://cdn.nlark.com/yuque/0/2025/png/46999547/1758964094269-4a2e023e-4ce3-4df9-94f7-46ac2d14e21e.png)

架构图

传统的LLM接受文本作为输入并且输出文本，但是MLLM还需要能够接受并且输出多模态的信息，就需要对多模态的信息做一个处理。主流MLLM再处理多模态的信息的时候，需要用一个特殊的多模态编码器，来把多模态信息转换为LLM可以读懂的信息，最后是LLM的推理和输出，如果是输出多模态的信息需要借助对应的生成器。

**预训练模态编码器**

作用：把多模态信息（audio、image，video）转换为更加紧凑的表示（more compact representation）通常选取已经在特定模态上已经对齐过的编码器，而非从0开始训练，比如clip在图像-文本信息上进行过对齐，使用这些预训练好的模型更加容易将多模态信息和LLM进行对齐。

**预训练大模型**

原文对这一部分没有过多地阐述，只提到Scaling Law依旧有效；以及提到MoE架构通过激活部分参数来实现增大模型参数量并且减少计算开销的效果。

**多模态交互**

补充，前面说编码器不是已经对齐了吗，那为什么还需要connector来连接编码器和LLM？

因为有的编码器没做对齐（如ConvNext）

直接训练end2end的模型开销太大，因此采取需要借助一个中间的媒介来沟通多模态信息和LLM。方法有两个：

1. 训练一个connector模块。包括token级别和feature级别的融合：

- token级别：将编码器输出的编码转换成token与文本token**拼接**后进入LLM。
- feature级别：使用了注意力机制把特征进行融合。

2. 使用专家模型：思想是使用专用的模型把其他模态的信息转换为text，但是灵活度不够

这一部分对应论文中的这一张图，最左边是token级别的connector：

![](https://cdn.nlark.com/yuque/0/2025/png/46999547/1758977027205-4b1bbde8-ef34-4731-aae5-aa7f6f224640.png)

---

## 训练策略

**预训练Pretraining**

预训练的目的有2个：1. 为了让大模型对齐多个模态的信息 2. 让模型获取到外部知识。以图像-文本为例，常见的方法是拿caption数据进行训练，冻结大部分模块，只训练少部分的模块（比如connector）

相关的数据集有：

- Coarse-Grained Data：数据多，但是质量参差不齐，比如CC
- Fined-Gained Data：数量少，并且质量高，比如ShareGPT4V

**指令微调Instruction tuning**

指令微调是指通过构建指令格式的实例，然后以**有监督**的方式对大语言模型进行微调，来帮助LLM**拥有更好的推理能力**， 从而展现出**泛化到未见过任务（zero-shot 0样本）**的卓越能力。

用于指令微调的数据样本可以用这样的一个三元组来表示$(I,M,G)$ 分别表示Instruction，Multimedia data 和Ground truth的结果 
**对齐微调**


---

后记：

1. 上个学期使用过zotero但是当时不知为何十分卡顿，今天尝试多个方案解决问题，最后发现的问题是：我把zotero的默认下载路径改到D盘。。。后续删除重新再C盘默认路径下载之后解决了问题。（使用zotero版本为7.x）
2. 目前使用ob来管理笔记，使用zotero阅读文章，缺少联动的方法。
3. 我发现自己了解过的相关知识阅读起来就很舒服，一旦在一大段里面多次出现自己不理解的概念，读起来就很难受了。