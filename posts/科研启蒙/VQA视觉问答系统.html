<!doctype html>
<html lang="zh-CN" data-theme="light">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width,initial-scale=1" />
    <meta name="generator" content="VuePress 2.0.0-rc.19" />
    <meta name="theme" content="VuePress Theme Hope 2.0.0-rc.67" />
    <style>
      :root {
        --vp-c-bg: #fff;
      }

      [data-theme="dark"] {
        --vp-c-bg: #1b1b1f;
      }

      html,
      body {
        background: var(--vp-c-bg);
      }
    </style>
    <script>
      const userMode = localStorage.getItem("vuepress-theme-hope-scheme");
      const systemDarkMode =
        window.matchMedia &&
        window.matchMedia("(prefers-color-scheme: dark)").matches;

      if (userMode === "dark" || (userMode !== "light" && systemDarkMode)) {
        document.documentElement.setAttribute("data-theme", "dark");
      }
    </script>
    <meta property="og:url" content="https://github.com/yama-lei/yama-lei.github.io/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/VQA%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F.html"><meta property="og:site_name" content="Myblog"><meta property="og:title" content="VQAè§†è§‰é—®ç­”ç³»ç»Ÿå­¦ä¹ ç¬”è®°"><meta property="og:description" content="VQA ç»¼è¿°é˜…è¯»ï¼š This passage is a reading note of a survey on VQA. Reading the raw passage is recommened:A Comprehensive Survey on Visual Question Answering Datasets and Algorithms Ab..."><meta property="og:type" content="article"><meta property="og:image" content="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/6fb85be2a08f15ce71245f1301d3b1ab.png"><meta property="og:locale" content="zh-CN"><meta property="og:updated_time" content="2025-04-04T12:29:07.000Z"><meta property="article:published_time" content="2025-02-14T00:00:00.000Z"><meta property="article:modified_time" content="2025-04-04T12:29:07.000Z"><script type="application/ld+json">{"@context":"https://schema.org","@type":"Article","headline":"VQAè§†è§‰é—®ç­”ç³»ç»Ÿå­¦ä¹ ç¬”è®°","image":["https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/6fb85be2a08f15ce71245f1301d3b1ab.png","https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/x1.png","https://pica.zhimg.com/v2-4452fdaaa04686aa270010f57f4db2aa_1440w.jpg","https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250322203830571.png","https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250322204019083.png"],"datePublished":"2025-02-14T00:00:00.000Z","dateModified":"2025-04-04T12:29:07.000Z","author":[{"@type":"Person","name":"Yama-lei","url":"/underbuilding.html"}]}</script><link rel="icon" href="/assets/icon/yama.svg"><title>VQAè§†è§‰é—®ç­”ç³»ç»Ÿå­¦ä¹ ç¬”è®° | Myblog</title><meta name="description" content="VQA ç»¼è¿°é˜…è¯»ï¼š This passage is a reading note of a survey on VQA. Reading the raw passage is recommened:A Comprehensive Survey on Visual Question Answering Datasets and Algorithms Ab...">
    <link rel="preload" href="/assets/style-HKakJfzV.css" as="style"><link rel="stylesheet" href="/assets/style-HKakJfzV.css">
    <link rel="modulepreload" href="/assets/app-CihjbUnI.js"><link rel="modulepreload" href="/assets/VQAè§†è§‰é—®ç­”ç³»ç»Ÿ.html-Bvg3TFN0.js">
    <link rel="prefetch" href="/assets/index.html-DgOlm9w_.js" as="script"><link rel="prefetch" href="/assets/intro.html-C2Rc_wCO.js" as="script"><link rel="prefetch" href="/assets/underbuilding.html-CLaaztQs.js" as="script"><link rel="prefetch" href="/assets/index.html-DGRorfUF.js" as="script"><link rel="prefetch" href="/assets/disable.html-1gZcfd9u.js" as="script"><link rel="prefetch" href="/assets/encrypt.html-BtCV5cV3.js" as="script"><link rel="prefetch" href="/assets/layout.html-Cy4zyv0j.js" as="script"><link rel="prefetch" href="/assets/markdown.html-Ca3diPmP.js" as="script"><link rel="prefetch" href="/assets/page.html-wVrUEHoM.js" as="script"><link rel="prefetch" href="/assets/index.html-CHL2AtXF.js" as="script"><link rel="prefetch" href="/assets/love.html-MN1KwdIO.js" as="script"><link rel="prefetch" href="/assets/index.html-C3mDC-ao.js" as="script"><link rel="prefetch" href="/assets/index.html-CpTQIXR8.js" as="script"><link rel="prefetch" href="/assets/index.html-B9iN0gu8.js" as="script"><link rel="prefetch" href="/assets/gitçš„ä½¿ç”¨.html-8XkWSidw.js" as="script"><link rel="prefetch" href="/assets/å®ç”¨ç½‘ç«™.html-BH_M3nxs.js" as="script"><link rel="prefetch" href="/assets/ç®€å•çš„å‘½ä»¤è¡Œæ“ä½œ.html-BZ6cFBk7.js" as="script"><link rel="prefetch" href="/assets/2025_3_13.html-DTFCXHhL.js" as="script"><link rel="prefetch" href="/assets/Letters.html-BJ_DYbQt.js" as="script"><link rel="prefetch" href="/assets/NewYearEve.html-oYyS76z2.js" as="script"><link rel="prefetch" href="/assets/index.html-B71ldbN0.js" as="script"><link rel="prefetch" href="/assets/RedMountainZoo.html-DU-6Y-01.js" as="script"><link rel="prefetch" href="/assets/SocialPractice.html-BthehJco.js" as="script"><link rel="prefetch" href="/assets/jhyz.html-CbnChHZ-.js" as="script"><link rel="prefetch" href="/assets/index.html-DefEteSm.js" as="script"><link rel="prefetch" href="/assets/Zhihu1.html-C2pIZhHa.js" as="script"><link rel="prefetch" href="/assets/Zhihu2.html-CAEzPYZW.js" as="script"><link rel="prefetch" href="/assets/beautifulSentence.html-CvTr9cn3.js" as="script"><link rel="prefetch" href="/assets/konwledges.html-C2x5YVYc.js" as="script"><link rel="prefetch" href="/assets/ä¸€ä½å¾ˆä¼˜ç§€çš„è€å¸ˆè¯´çš„è¯.html-B19KBDIK.js" as="script"><link rel="prefetch" href="/assets/01èƒŒåŒ….html-DOGy8Hew.js" as="script"><link rel="prefetch" href="/assets/classç»¼åˆ.html-CWXWb0uM.js" as="script"><link rel="prefetch" href="/assets/äºŒåˆ†æŸ¥æ‰¾.html-aMEJViBw.js" as="script"><link rel="prefetch" href="/assets/æœç´¢.html-DbrpwSSX.js" as="script"><link rel="prefetch" href="/assets/æš´åŠ›æšä¸¾å’Œé€’å½’.html-CEFDN7Tb.js" as="script"><link rel="prefetch" href="/assets/List.html-CSlGU4-m.js" as="script"><link rel="prefetch" href="/assets/sicpç¬”è®°.html-DA_fDaqh.js" as="script"><link rel="prefetch" href="/assets/async function.html-W6y9IdPX.js" as="script"><link rel="prefetch" href="/assets/pinia.html-Ci3PN_H1.js" as="script"><link rel="prefetch" href="/assets/vue3çš„å“åº”å¼æ•°æ®.html-LQyJZt0k.js" as="script"><link rel="prefetch" href="/assets/å…ƒç´ çš„è®¿é—®.html-CahogG4u.js" as="script"><link rel="prefetch" href="/assets/å›¾åºŠé…ç½®.html-CizMGdSx.js" as="script"><link rel="prefetch" href="/assets/å¸ƒå±€æ–¹å¼.html-C9pXoW6J.js" as="script"><link rel="prefetch" href="/assets/æ’æ§½.html-ZNodWs6F.js" as="script"><link rel="prefetch" href="/assets/ç»„ä»¶çš„ç”Ÿå‘½å‘¨æœŸ.html-DZjUcLA_.js" as="script"><link rel="prefetch" href="/assets/ç»„ä»¶é€šä¿¡.html-BC8wAXO-.js" as="script"><link rel="prefetch" href="/assets/è‡ªå®šä¹‰äº‹ä»¶ä¸ç›‘è§†.html-DvK2Fmjw.js" as="script"><link rel="prefetch" href="/assets/è·¯ç”±.html-1_d5mLWu.js" as="script"><link rel="prefetch" href="/assets/Anacondaçš„å­¦ä¹ .html-d3hNstmY.js" as="script"><link rel="prefetch" href="/assets/Pytorchå­¦ä¹ .html-_jc9DGBk.js" as="script"><link rel="prefetch" href="/assets/ä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡å™¨è®­ç»ƒæ¨¡å‹.html-Dhq5EO7h.js" as="script"><link rel="prefetch" href="/assets/å­¦é•¿åˆ†äº«.html-dlGOO5W3.js" as="script"><link rel="prefetch" href="/assets/ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ¦‚å¿µ.html-D84lQVzL.js" as="script"><link rel="prefetch" href="/assets/é“¾æ¥å®éªŒå®¤çš„æœåŠ¡å™¨.html-DFQx64AQ.js" as="script"><link rel="prefetch" href="/assets/Drama-English-Version.html-bE1dDQBK.js" as="script"><link rel="prefetch" href="/assets/å‘¨ä¸€æˆå‰§.html-DY14_Oie.js" as="script"><link rel="prefetch" href="/assets/è‹±è¯­å‘¨ä¸€.html-BAEdcPmw.js" as="script"><link rel="prefetch" href="/assets/è‹±è¯­å‘¨ä¸‰.html-BeDQj7io.js" as="script"><link rel="prefetch" href="/assets/FPGAè®¾è®¡å’Œç¡¬ä»¶æè¿°è¯­è¨€.html-DKiK64ol.js" as="script"><link rel="prefetch" href="/assets/logisimå®éªŒ.html-BlVbCURe.js" as="script"><link rel="prefetch" href="/assets/ä¸“é¢˜ï¼šå„ç§å¯„å­˜å™¨çš„ç›¸äº’è½¬æ¢.html-BXHeRY32.js" as="script"><link rel="prefetch" href="/assets/äºŒè¿›åˆ¶è¡¨ç¤º.html-fKAK08Sm.js" as="script"><link rel="prefetch" href="/assets/ä½œä¸šï¼šç¬¬å››ç« .html-C5SlPmMF.js" as="script"><link rel="prefetch" href="/assets/æ•°å­—é€»è¾‘åŸºç¡€.html-JvEJC73I.js" as="script"><link rel="prefetch" href="/assets/æ—¶åºé€»è¾‘ç”µè·¯.html-DWjS62iX.js" as="script"><link rel="prefetch" href="/assets/ç»„åˆé€»è¾‘ç”µè·¯.html-BwLDlwwm.js" as="script"><link rel="prefetch" href="/assets/è¿ç®—æ–¹æ³•å’Œè¿ç®—éƒ¨ä»¶.html-5I7levFk.js" as="script"><link rel="prefetch" href="/assets/æ™®é€šç‰©ç†å­¦.html-BKJegAG0.js" as="script"><link rel="prefetch" href="/assets/FileOperation.html-DIFaLArK.js" as="script"><link rel="prefetch" href="/assets/PA1.html-BxbX527D.js" as="script"><link rel="prefetch" href="/assets/STLå®¹å™¨.html-Bs3u8mWl.js" as="script"><link rel="prefetch" href="/assets/class.html-DwI5MQJ_.js" as="script"><link rel="prefetch" href="/assets/stlç®—æ³•.html-BZA4PkWh.js" as="script"><link rel="prefetch" href="/assets/string.html-Bnl4BTF9.js" as="script"><link rel="prefetch" href="/assets/æ’åº.html-BBe3pPkE.js" as="script"><link rel="prefetch" href="/assets/ç¨‹åºè®¾è®¡åŸºç¡€æœŸæœ«å¤ä¹ .html-Curcg8sH.js" as="script"><link rel="prefetch" href="/assets/è¯¾ç¨‹å®‰æ’.html-BxlmVCoG.js" as="script"><link rel="prefetch" href="/assets/è¯¾ç¨‹ç¬”è®°.html-DCS3YqcZ.js" as="script"><link rel="prefetch" href="/assets/æœ€ä¼šæ±‡æŠ¥week4.html-B-ccxJ4v.js" as="script"><link rel="prefetch" href="/assets/ç»„ä¼šæ±‡æŠ¥week1.html-BGnuCo9G.js" as="script"><link rel="prefetch" href="/assets/ç»„ä¼šæ±‡æŠ¥week2.html-DLXQQajP.js" as="script"><link rel="prefetch" href="/assets/ç»„ä¼šæ±‡æŠ¥week3.html-D5C5R0NA.js" as="script"><link rel="prefetch" href="/assets/1.html-C4_HxxBI.js" as="script"><link rel="prefetch" href="/assets/404.html-CTfN6jgB.js" as="script"><link rel="prefetch" href="/assets/index.html-WEYt2Nmq.js" as="script"><link rel="prefetch" href="/assets/index.html-Br8Ko5A1.js" as="script"><link rel="prefetch" href="/assets/index.html-BFYQX6PE.js" as="script"><link rel="prefetch" href="/assets/index.html-bi7KFb2h.js" as="script"><link rel="prefetch" href="/assets/index.html-DYomn9-G.js" as="script"><link rel="prefetch" href="/assets/index.html-BrHDrdhH.js" as="script"><link rel="prefetch" href="/assets/index.html-BG04x7d_.js" as="script"><link rel="prefetch" href="/assets/index.html-CG57ekID.js" as="script"><link rel="prefetch" href="/assets/index.html-GWwCZM5o.js" as="script"><link rel="prefetch" href="/assets/index.html-DUgnDGrV.js" as="script"><link rel="prefetch" href="/assets/index.html-DLBgI5MM.js" as="script"><link rel="prefetch" href="/assets/index.html-Dmevm_Yn.js" as="script"><link rel="prefetch" href="/assets/index.html-Bl27LKCm.js" as="script"><link rel="prefetch" href="/assets/index.html-PEYFAw0H.js" as="script"><link rel="prefetch" href="/assets/index.html-C9BkEsqt.js" as="script"><link rel="prefetch" href="/assets/index.html-Db2SXs0T.js" as="script"><link rel="prefetch" href="/assets/index.html-c0Xm0UQM.js" as="script"><link rel="prefetch" href="/assets/index.html-1N9ML2Ll.js" as="script"><link rel="prefetch" href="/assets/index.html-DCYdgA3t.js" as="script"><link rel="prefetch" href="/assets/auto-Q-Ce4MY6.js" as="script"><link rel="prefetch" href="/assets/reveal.esm-B3O8JSaZ.js" as="script"><link rel="prefetch" href="/assets/markdown.esm-DotuGrRK.js" as="script"><link rel="prefetch" href="/assets/highlight.esm-BAQT6v9A.js" as="script"><link rel="prefetch" href="/assets/math.esm-Cgto3ffo.js" as="script"><link rel="prefetch" href="/assets/search.esm-BPaPUgSs.js" as="script"><link rel="prefetch" href="/assets/notes.esm-DugvsDbc.js" as="script"><link rel="prefetch" href="/assets/zoom.esm-BPsgJ1Hi.js" as="script"><link rel="prefetch" href="/assets/photoswipe.esm-CMg0yb1C.js" as="script"><link rel="prefetch" href="/assets/setupDevtools-7MC2TMWH-Cj-9ep8Z.js" as="script">
  </head>
  <body>
    <div id="app"><!--[--><!--[--><!--[--><span tabindex="-1"></span><a href="#main-content" class="vp-skip-link sr-only">è·³è‡³ä¸»è¦å…§å®¹</a><!--]--><div class="theme-container external-link-icon has-toc" vp-container><!--[--><header id="navbar" class="vp-navbar" vp-navbar><div class="vp-navbar-start"><button type="button" class="vp-toggle-sidebar-button" title="Toggle Sidebar"><span class="icon"></span></button><!--[--><a class="route-link vp-brand" href="/" aria-label="å¸¦æˆ‘å›å®¶"><img class="vp-nav-logo" src="/assets/icon/yamasun.svg" alt><!----><span class="vp-site-name hide-in-pad">Myblog</span></a><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--]--></div><div class="vp-navbar-center"><!--[--><nav class="vp-nav-links"><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/" aria-label="åšå®¢ä¸»é¡µ"><!--[--><i class="vp-icon fas fa-home" style=""></i><!--]-->åšå®¢ä¸»é¡µ<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/thinking/" aria-label="äººç”Ÿæ„Ÿæ‚Ÿ"><!--[--><img class="vp-icon" src="/assets/icon/thinking.svg" alt aria-hidden no-view style=""><!--]-->äººç”Ÿæ„Ÿæ‚Ÿ<!----></a></div><div class="vp-nav-item hide-in-mobile"><div class="vp-dropdown-wrapper"><button type="button" class="vp-dropdown-title" aria-label="åšæ–‡"><!--[--><i class="vp-icon fas fa-pen-to-square" style=""></i>åšæ–‡<!--]--><span class="arrow"></span><ul class="vp-dropdown"><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/python%E5%AD%A6%E4%B9%A0/" aria-label="python"><!---->python<!----></a></li><li class="vp-dropdown-item"><a class="route-link auto-link" href="/posts/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/" aria-label="å‰ç«¯å¼€å‘"><!---->å‰ç«¯å¼€å‘<!----></a></li><li class="vp-dropdown-item"><a class="route-link route-link-active auto-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/" aria-label="ç§‘ç ”å¯è’™"><!---->ç§‘ç ”å¯è’™<!----></a></li><li class="vp-dropdown-item"><h4 class="vp-dropdown-subtitle"><a class="route-link auto-link" href="/posts/NJUCS/" aria-label="NJUCS"><!---->NJUCS<!----></a></h4><ul class="vp-dropdown-subitems"><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/NJUCS/%E9%AB%98%E7%BA%A7%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1/" aria-label="é«˜çº§ç¨‹åºè®¾è®¡"><!---->é«˜çº§ç¨‹åºè®¾è®¡<!----></a></li><li class="vp-dropdown-subitem"><a class="route-link auto-link" href="/posts/NJUCS/%E6%95%B0%E5%AD%97%E9%80%BB%E8%BE%91%E4%B8%8E%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%84%E6%88%90/" aria-label="æ•°å­—é€»è¾‘ä¸è®¡ç®—æœºç»„æˆ"><!---->æ•°å­—é€»è¾‘ä¸è®¡ç®—æœºç»„æˆ<!----></a></li></ul></li></ul></button></div></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/posts/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/" aria-label="å‰ç«¯å¼€å‘"><!--[--><i class="vp-icon fas fa-pen-to-square" style=""></i><!--]-->å‰ç«¯å¼€å‘<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link auto-link" href="/posts/NJUCS/" aria-label="NJUCSå—å¤§è®¡ç®—æœºç¬”è®°"><!--[--><img class="vp-icon" src="/assets/icon/nju.svg" alt aria-hidden no-view style=""><!--]-->NJUCSå—å¤§è®¡ç®—æœºç¬”è®°<!----></a></div><div class="vp-nav-item hide-in-mobile"><a class="route-link route-link-active auto-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/" aria-label="ç§‘ç ”å¯è’™"><!--[--><img class="vp-icon" src="/assets/icon/nju.svg" alt aria-hidden no-view style=""><!--]-->ç§‘ç ”å¯è’™<!----></a></div></nav><!----><!--]--></div><div class="vp-navbar-end"><!--[--><!----><div class="vp-nav-item vp-action"><a class="vp-action-link" href="https://github.com/yama-lei/yama-lei.github.io" target="_blank" rel="noopener noreferrer" aria-label="GitHub"><svg xmlns="http://www.w3.org/2000/svg" class="icon github-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="github icon" name="github" style="width:1.25rem;height:1.25rem;vertical-align:middle;"><path d="M511.957 21.333C241.024 21.333 21.333 240.981 21.333 512c0 216.832 140.544 400.725 335.574 465.664 24.49 4.395 32.256-10.07 32.256-23.083 0-11.69.256-44.245 0-85.205-136.448 29.61-164.736-64.64-164.736-64.64-22.315-56.704-54.4-71.765-54.4-71.765-44.587-30.464 3.285-29.824 3.285-29.824 49.195 3.413 75.179 50.517 75.179 50.517 43.776 75.008 114.816 53.333 142.762 40.79 4.523-31.66 17.152-53.377 31.19-65.537-108.971-12.458-223.488-54.485-223.488-242.602 0-53.547 19.114-97.323 50.517-131.67-5.035-12.33-21.93-62.293 4.779-129.834 0 0 41.258-13.184 134.912 50.346a469.803 469.803 0 0 1 122.88-16.554c41.642.213 83.626 5.632 122.88 16.554 93.653-63.488 134.784-50.346 134.784-50.346 26.752 67.541 9.898 117.504 4.864 129.834 31.402 34.347 50.474 78.123 50.474 131.67 0 188.586-114.73 230.016-224.042 242.09 17.578 15.232 33.578 44.672 33.578 90.454v135.85c0 13.142 7.936 27.606 32.854 22.87C862.25 912.597 1002.667 728.747 1002.667 512c0-271.019-219.648-490.667-490.71-490.667z"></path></svg></a></div><div class="vp-nav-item hide-in-mobile"><button type="button" class="vp-color-mode-switch" id="color-mode-switch"><svg xmlns="http://www.w3.org/2000/svg" class="icon auto-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="auto icon" name="auto" style="display:block;"><path d="M512 992C246.92 992 32 777.08 32 512S246.92 32 512 32s480 214.92 480 480-214.92 480-480 480zm0-840c-198.78 0-360 161.22-360 360 0 198.84 161.22 360 360 360s360-161.16 360-360c0-198.78-161.22-360-360-360zm0 660V212c165.72 0 300 134.34 300 300 0 165.72-134.28 300-300 300z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon dark-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="dark icon" name="dark" style="display:none;"><path d="M524.8 938.667h-4.267a439.893 439.893 0 0 1-313.173-134.4 446.293 446.293 0 0 1-11.093-597.334A432.213 432.213 0 0 1 366.933 90.027a42.667 42.667 0 0 1 45.227 9.386 42.667 42.667 0 0 1 10.24 42.667 358.4 358.4 0 0 0 82.773 375.893 361.387 361.387 0 0 0 376.747 82.774 42.667 42.667 0 0 1 54.187 55.04 433.493 433.493 0 0 1-99.84 154.88 438.613 438.613 0 0 1-311.467 128z"></path></svg><svg xmlns="http://www.w3.org/2000/svg" class="icon light-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="light icon" name="light" style="display:none;"><path d="M952 552h-80a40 40 0 0 1 0-80h80a40 40 0 0 1 0 80zM801.88 280.08a41 41 0 0 1-57.96-57.96l57.96-58a41.04 41.04 0 0 1 58 58l-58 57.96zM512 752a240 240 0 1 1 0-480 240 240 0 0 1 0 480zm0-560a40 40 0 0 1-40-40V72a40 40 0 0 1 80 0v80a40 40 0 0 1-40 40zm-289.88 88.08-58-57.96a41.04 41.04 0 0 1 58-58l57.96 58a41 41 0 0 1-57.96 57.96zM192 512a40 40 0 0 1-40 40H72a40 40 0 0 1 0-80h80a40 40 0 0 1 40 40zm30.12 231.92a41 41 0 0 1 57.96 57.96l-57.96 58a41.04 41.04 0 0 1-58-58l58-57.96zM512 832a40 40 0 0 1 40 40v80a40 40 0 0 1-80 0v-80a40 40 0 0 1 40-40zm289.88-88.08 58 57.96a41.04 41.04 0 0 1-58 58l-57.96-58a41 41 0 0 1 57.96-57.96z"></path></svg></button></div><!--]--><button type="button" class="vp-toggle-navbar-button" aria-label="Toggle Navbar" aria-expanded="false" aria-controls="nav-screen"><span><span class="vp-top"></span><span class="vp-middle"></span><span class="vp-bottom"></span></span></button></div></header><!----><!--]--><!----><div class="toggle-sidebar-wrapper"><span class="arrow start"></span></div><aside id="sidebar" class="vp-sidebar" vp-sidebar><!----><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/" aria-label="åšå®¢ä¸»é¡µ"><!--[--><i class="vp-icon fas fa-home" style=""></i><!--]-->åšå®¢ä¸»é¡µ<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><i class="vp-icon fas fa-book" style=""></i><span class="vp-sidebar-title">æ–‡ç« </span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/git%E7%9A%84%E4%BD%BF%E7%94%A8.html" aria-label="githubå…¥é—¨--the missing class for cs learner"><!---->githubå…¥é—¨--the missing class for cs learner<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">NJUCS</span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">OJéš¾é¢˜ç§¯ç´¯ä¸å­¦ä¹ </span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">Pythonå­¦ä¹ </span><span class="vp-arrow end"></span></button><!----></section></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">å‰ç«¯å¼€å‘</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E5%AE%9E%E7%94%A8%E7%BD%91%E7%AB%99.html" aria-label="å®ç”¨ç½‘ç«™"><!---->å®ç”¨ç½‘ç«™<!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable active" type="button"><!----><span class="vp-sidebar-title">ç§‘ç ”å¯è’™</span><span class="vp-arrow down"></span></button><ul class="vp-sidebar-links"><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/Pytorch%E5%AD%A6%E4%B9%A0.html" aria-label="Pytorchå­¦ä¹ "><!---->Pytorchå­¦ä¹ <!----></a></li><li><section class="vp-sidebar-group"><button class="vp-sidebar-header clickable" type="button"><!----><span class="vp-sidebar-title">VQAlearning</span><span class="vp-arrow end"></span></button><!----></section></li><li><a class="route-link route-link-active auto-link vp-sidebar-link active" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/VQA%E8%A7%86%E8%A7%89%E9%97%AE%E7%AD%94%E7%B3%BB%E7%BB%9F.html" aria-label="VQAè§†è§‰é—®ç­”ç³»ç»Ÿå­¦ä¹ ç¬”è®°"><!---->VQAè§†è§‰é—®ç­”ç³»ç»Ÿå­¦ä¹ ç¬”è®°<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html" aria-label="ä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡å™¨è®­ç»ƒæ¨¡å‹"><!---->ä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡å™¨è®­ç»ƒæ¨¡å‹<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/Anaconda%E7%9A%84%E5%AD%A6%E4%B9%A0.html" aria-label="å­¦ä¹ Anaconda"><!---->å­¦ä¹ Anaconda<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/%E5%AD%A6%E9%95%BF%E5%88%86%E4%BA%AB.html" aria-label="æ—©æœŸç§‘ç ”å‡†å¤‡--AIå²æµ©å—"><!---->æ—©æœŸç§‘ç ”å‡†å¤‡--AIå²æµ©å—<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5.html" aria-label="ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ¦‚å¿µ"><!---->ç¥ç»ç½‘ç»œçš„åŸºæœ¬æ¦‚å¿µ<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/%E9%93%BE%E6%8E%A5%E5%AE%9E%E9%AA%8C%E5%AE%A4%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8.html" aria-label="è¿æ¥å®éªŒå®¤çš„æœåŠ¡å™¨"><!---->è¿æ¥å®éªŒå®¤çš„æœåŠ¡å™¨<!----></a></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/posts/%E7%AE%80%E5%8D%95%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E6%93%8D%E4%BD%9C.html" aria-label="ç®€å•çš„å‘½ä»¤è¡Œæ“ä½œ"><!---->ç®€å•çš„å‘½ä»¤è¡Œæ“ä½œ<!----></a></li></ul></section></li><li><a class="route-link auto-link vp-sidebar-link" href="/intro.html" aria-label="ä¸ªäººç®€ä»‹"><!--[--><img class="vp-icon" src="/assets/icon/intro.svg" alt aria-hidden no-view style=""><!--]-->ä¸ªäººç®€ä»‹<!----></a></li><li><a class="route-link auto-link vp-sidebar-link" href="/game/" aria-label="game"><!--[--><img class="vp-icon" src="/assets/icon/game.svg" alt aria-hidden no-view style=""><!--]-->game<!----></a></li></ul><!----></aside><!--[--><main id="main-content" class="vp-page"><!--[--><!----><!----><nav class="vp-breadcrumb disable"></nav><div class="vp-page-title"><h1><!---->VQAè§†è§‰é—®ç­”ç³»ç»Ÿå­¦ä¹ ç¬”è®°</h1><div class="page-info"><span class="page-author-info" aria-label="ä½œè€…ğŸ–Š" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon author-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="author icon" name="author"><path d="M649.6 633.6c86.4-48 147.2-144 147.2-249.6 0-160-128-288-288-288s-288 128-288 288c0 108.8 57.6 201.6 147.2 249.6-121.6 48-214.4 153.6-240 288-3.2 9.6 0 19.2 6.4 25.6 3.2 9.6 12.8 12.8 22.4 12.8h704c9.6 0 19.2-3.2 25.6-12.8 6.4-6.4 9.6-16 6.4-25.6-25.6-134.4-121.6-240-243.2-288z"></path></svg><span><a class="page-author-item" href="/underbuilding.html" target="_blank" rel="noopener noreferrer">Yama-lei</a></span><span property="author" content="Yama-lei"></span></span><!----><span class="page-date-info" aria-label="å†™ä½œæ—¥æœŸğŸ“…" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon calendar-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="calendar icon" name="calendar"><path d="M716.4 110.137c0-18.753-14.72-33.473-33.472-33.473-18.753 0-33.473 14.72-33.473 33.473v33.473h66.993v-33.473zm-334.87 0c0-18.753-14.72-33.473-33.473-33.473s-33.52 14.72-33.52 33.473v33.473h66.993v-33.473zm468.81 33.52H716.4v100.465c0 18.753-14.72 33.473-33.472 33.473a33.145 33.145 0 01-33.473-33.473V143.657H381.53v100.465c0 18.753-14.72 33.473-33.473 33.473a33.145 33.145 0 01-33.473-33.473V143.657H180.6A134.314 134.314 0 0046.66 277.595v535.756A134.314 134.314 0 00180.6 947.289h669.74a134.36 134.36 0 00133.94-133.938V277.595a134.314 134.314 0 00-133.94-133.938zm33.473 267.877H147.126a33.145 33.145 0 01-33.473-33.473c0-18.752 14.72-33.473 33.473-33.473h736.687c18.752 0 33.472 14.72 33.472 33.473a33.145 33.145 0 01-33.472 33.473z"></path></svg><span data-allow-mismatch="text">2025å¹´2æœˆ14æ—¥</span><meta property="datePublished" content="2025-02-14T00:00:00.000Z"></span><!----><span class="page-reading-time-info" aria-label="é˜…è¯»æ—¶é—´âŒ›" data-balloon-pos="up"><svg xmlns="http://www.w3.org/2000/svg" class="icon timer-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="timer icon" name="timer"><path d="M799.387 122.15c4.402-2.978 7.38-7.897 7.38-13.463v-1.165c0-8.933-7.38-16.312-16.312-16.312H256.33c-8.933 0-16.311 7.38-16.311 16.312v1.165c0 5.825 2.977 10.874 7.637 13.592 4.143 194.44 97.22 354.963 220.201 392.763-122.204 37.542-214.893 196.511-220.2 389.397-4.661 5.049-7.638 11.651-7.638 19.03v5.825h566.49v-5.825c0-7.379-2.849-13.981-7.509-18.9-5.049-193.016-97.867-351.985-220.2-389.527 123.24-37.67 216.446-198.453 220.588-392.892zM531.16 450.445v352.632c117.674 1.553 211.787 40.778 211.787 88.676H304.097c0-48.286 95.149-87.382 213.728-88.676V450.445c-93.077-3.107-167.901-81.297-167.901-177.093 0-8.803 6.99-15.793 15.793-15.793 8.803 0 15.794 6.99 15.794 15.793 0 80.261 63.69 145.635 142.01 145.635s142.011-65.374 142.011-145.635c0-8.803 6.99-15.793 15.794-15.793s15.793 6.99 15.793 15.793c0 95.019-73.789 172.82-165.96 177.093z"></path></svg><span>å¤§çº¦ 15 åˆ†é’Ÿ</span><meta property="timeRequired" content="PT15M"></span><!----><!----></div><hr></div><div class="vp-toc-placeholder"><aside id="toc" vp-toc><!----><!--[--><div class="vp-toc-header">æ­¤é¡µå†…å®¹<button type="button" class="print-button" title="æ‰“å°"><svg xmlns="http://www.w3.org/2000/svg" class="icon print-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="print icon" name="print"><path d="M819.2 364.8h-44.8V128c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v236.8h-44.8C145.067 364.8 96 413.867 96 473.6v192c0 59.733 49.067 108.8 108.8 108.8h44.8V896c0 17.067 14.933 32 32 32h460.8c17.067 0 32-14.933 32-32V774.4h44.8c59.733 0 108.8-49.067 108.8-108.8v-192c0-59.733-49.067-108.8-108.8-108.8zM313.6 160h396.8v204.8H313.6V160zm396.8 704H313.6V620.8h396.8V864zM864 665.6c0 25.6-19.2 44.8-44.8 44.8h-44.8V588.8c0-17.067-14.933-32-32-32H281.6c-17.067 0-32 14.933-32 32v121.6h-44.8c-25.6 0-44.8-19.2-44.8-44.8v-192c0-25.6 19.2-44.8 44.8-44.8h614.4c25.6 0 44.8 19.2 44.8 44.8v192z"></path></svg></button><div class="arrow end"></div></div><div class="vp-toc-wrapper"><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#abstract">Abstract:</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#datasets">Datasets</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#general-datasets">General datasets</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#synthetic-datasets-è™šæ„çš„">Synthetic datasets (è™šæ„çš„)</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#dignostic-datasets">Dignostic datasets</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#kb-datasets">KB datasets</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#evaluation-datasets">Evaluation datasets</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#algoritms">Algoritms</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#image-representation">Image Representation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#questions-representation">Questions Representation</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#fusion-and-attention">Fusion and Attention</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#answering">Answering</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#mutilmodel-fusion">Mutilmodel Fusion</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#attention">Attention</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#external-knowledge">External Knowledge</a></li><!----><!--]--></ul></li><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level2" href="#vqaç®—æ³•">VQAç®—æ³•</a></li><li><ul class="vp-toc-list"><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#å¤šæ¨¡æ€èåˆ">å¤šæ¨¡æ€èåˆ</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#å›ç­”ç”Ÿæˆç®—æ³•">å›ç­”ç”Ÿæˆç®—æ³•</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#å°è¯•">å°è¯•</a></li><!----><!--]--><!--[--><li class="vp-toc-item"><a class="route-link vp-toc-link level3" href="#æœ‰å…³vqaå­¦ä¹ çš„ç–‘æƒ‘">æœ‰å…³VQAå­¦ä¹ çš„ç–‘æƒ‘</a></li><!----><!--]--></ul></li><!--]--></ul><div class="vp-toc-marker" style="top:-1.7rem;"></div></div><!--]--><!----></aside></div><!----><div class="theme-hope-content" vp-content><h1 id="vqa-ç»¼è¿°é˜…è¯»" tabindex="-1"><a class="header-anchor" href="#vqa-ç»¼è¿°é˜…è¯»"><span>VQA ç»¼è¿°é˜…è¯»ï¼š</span></a></h1><blockquote><p>This passage is a reading note of a survey on VQA. Reading the raw passage is recommened:<a href="https://arxiv.org/pdf/2411.11150" target="_blank" rel="noopener noreferrer">A Comprehensive Survey on Visual Question Answering Datasets and Algorithms</a></p></blockquote><h2 id="abstract" tabindex="-1"><a class="header-anchor" href="#abstract"><span>Abstract:</span></a></h2><p><strong>Datasets</strong>: We can devide the datasets of VQA into 4 catecories, namely:</p><p>â€¢Available datasets that contain a rich collection of authentic images<br> â€¢Synthetic datasets that contain only synthetic images produced through artificial means<br> â€¢Diagnostic datasets that are specially designed to test model performance in a particular area, e.g., understanding the scene text<br> â€¢KB (Knowledge-Based) datasets that are designed to measure a modelâ€™s ability to utilize outside knowledge</p><p><strong>Main paradigms</strong>: In this survey, we wlii explore six main paradigms:</p><ul><li>Fusion is where we discuss different methods of fusing information between visual and textual modalities.</li><li>Attention is the technique of using information from one modality to filter information from another. External knowledge base where we discuss different models utilizing outside information.</li><li>Composition or Reasoning, where we analyze techniques to answer advanced questions that require complex reasoning steps.</li><li>Explanation, which is the process of generating visual and/or textual descriptions to verify<br> sound Reasoning.</li><li>Graph models which encode and manipulate relationships through nodes in a graph.</li></ul><p>We also discuss some miscellaneous topics, such as scene text understanding, counting, and bias reduction.</p><p><strong>Problems</strong>: VQA compasses the following questions:</p><p>â€¢ Object recognition: What is behind the chair?<br> â€¢ Object detection: Are there any people in the image?<br> â€¢ Counting: How many dogs are there?<br> â€¢ Scene classification: Is it raining?<br> â€¢ Attribute classification: Is the person happy?</p><h2 id="datasets" tabindex="-1"><a class="header-anchor" href="#datasets"><span>Datasets</span></a></h2><h3 id="general-datasets" tabindex="-1"><a class="header-anchor" href="#general-datasets"><span>General datasets</span></a></h3><p>General datasets are the largest, richest, and most used datasets in VQA. General datasets contain many thousands of<br> real-world images from mainstream image datasets like MSCOCO [74] and Imagenet [32]. These datasets are notable for<br> their large scope and diversity. This variety is important as VQA datasets need to reflect the general nature of VQA. Although<br> these datasets do not necessarily capture the endless complexity and variety of visuals in real life, they achieve a close approximation.</p><figure><img src="/assets/image-20250222220048981-s6BiDDDb.png" alt="image-20250222220048981" tabindex="0" loading="lazy"><figcaption>image-20250222220048981</figcaption></figure><h3 id="synthetic-datasets-è™šæ„çš„" tabindex="-1"><a class="header-anchor" href="#synthetic-datasets-è™šæ„çš„"><span>Synthetic datasets (è™šæ„çš„)</span></a></h3><p>Synthetic datasets contain artificial images, produced using software, instead of real images. A good VQA model should<br> be able to perform well on both real and synthetic data like humans do. Synthetic datasets are easier, less expensive, and<br> less time-consuming to produce as the building of a large dataset can be automated. Synthetic datasets can be tailored<br> so that performing well on them requires better reasoning and composition skills.</p><figure><img src="/assets/image-20250222220150232-DikqilHw.png" alt="image-20250222220150232" tabindex="0" loading="lazy"><figcaption>image-20250222220150232</figcaption></figure><h3 id="dignostic-datasets" tabindex="-1"><a class="header-anchor" href="#dignostic-datasets"><span>Dignostic datasets</span></a></h3><p>Diagnostic datasets are specialized in the sense that they test a modelâ€™s ability in a particular area. They are usually small in size and are meant to complement larger, more general datasets by diagnosing the modelâ€™s performance in a distinct area which may not have pronounced results in the more general dataset.</p><figure><img src="/assets/image-20250223085514869-DkGfkt8P.png" alt="image-20250223085514869" tabindex="0" loading="lazy"><figcaption>image-20250223085514869</figcaption></figure><h3 id="kb-datasets" tabindex="-1"><a class="header-anchor" href="#kb-datasets"><span>KB datasets</span></a></h3><p>Sometimes it is not possible to answer a question with only the information present in the image. In such cases, the required knowledge has to be acquired from external sources. This is where KB datasets come in. They provide questions that require finding and using external knowledge. KB datasets can teach a model to know when it needs to search for absent knowledge and how to acquire that knowledge.</p><figure><img src="/assets/image-20250223090140313-BNLcl2ZU.png" alt="image-20250223090140313" tabindex="0" loading="lazy"><figcaption>image-20250223090140313</figcaption></figure><h3 id="evaluation-datasets" tabindex="-1"><a class="header-anchor" href="#evaluation-datasets"><span>Evaluation datasets</span></a></h3><p>A modelâ€™s performance being correctly evaluated depends on the evaluation metric used. Unfortunately, a major problem of VQA is that there is no widely agreed upon evaluation metric. Many different metrics have been proposed.</p><h2 id="algoritms" tabindex="-1"><a class="header-anchor" href="#algoritms"><span>Algoritms</span></a></h2><h3 id="image-representation" tabindex="-1"><a class="header-anchor" href="#image-representation"><span>Image Representation</span></a></h3><p><strong>1. CNN</strong></p><ul><li>When given an input image, a CNN goes through several convolution and pooling layers to produce a C Ã— W Ã— H shaped output.</li><li>Devide the image into grids</li><li>Problem: be distracted by noise (could be solved by Attention mechanism); one boject could be devided into multi adjacent blocks.</li></ul><p><strong>2. Object Detection</strong></p><ul><li><p>Example: Fast R-CNN</p></li><li><p>They produce multiple bounding boxes. Each bounding box usually contains an object belonging to a specific object class.</p></li><li><p>Devide the image into multiple &#39;bounding box&#39;</p></li><li><p>Problem: possible information loss (some information that is not in the bounding boxes would be dismissed)</p></li></ul><figure><img src="/assets/image-20250223092722130-4QpZfG2a.png" alt="image-20250223092722130" tabindex="0" loading="lazy"><figcaption>image-20250223092722130</figcaption></figure><p>â€‹ <strong>CNN(left) and Faster R-CNN(right).</strong></p><h3 id="questions-representation" tabindex="-1"><a class="header-anchor" href="#questions-representation"><span>Questions Representation</span></a></h3><p>Question representation in VQA is usually done by first embedding individual words and then using an RNN or a CNN to produce an embedding of the entire question.</p><blockquote><p>Here are the explanations from Grok3:</p><ol><li><p>Take a question like &quot;What color is the car?&quot;</p></li><li><p><strong>Embed individual words</strong>: Convert each word into a vector using a word embedding technique (e.g., &quot;What&quot; â†’ [0.1, 0.3, ...], &quot;color&quot; â†’ [0.4, -0.1, ...], etc.).</p></li><li><p><strong>Process with an RNN or CNN</strong>:</p><ul><li><p>RNN: Feed the vectors in sequence, and the final hidden state is the question embedding.</p></li><li><p>CNN: Apply filters to the sequence, pool the results, and get the question embedding.</p></li></ul></li><li><p>The output is a single vector representing the whole question, which the VQA model can then combine with image features to generate an answer.</p></li></ol></blockquote><h3 id="fusion-and-attention" tabindex="-1"><a class="header-anchor" href="#fusion-and-attention"><span>Fusion and Attention</span></a></h3><p>We will tlk about it in the following part</p><h3 id="answering" tabindex="-1"><a class="header-anchor" href="#answering"><span>Answering</span></a></h3><p>Hereâ€™s a quick summary of how &quot;answering&quot; works in Visual Question Answering (VQA) based on the &quot;Answering&quot; section (D) from the surveyâ€™s algorithm part:</p><p>In VQA, answering can be <strong>open-ended</strong> (free-form answers) or <strong>multiple-choice</strong> (choosing from options). There are two main ways to predict answers for open-ended VQA:</p><ol><li><p><strong>Non-Generative Approach</strong> (Most Common):</p><ul><li>Treats answers as predefined classes (e.g., all unique answers in the dataset).</li><li>Two types: <ul><li><strong>Single-Label Classification</strong>: The model predicts one answer by outputting a probability distribution (using softmax) over all possible answers, trained to maximize the probability of the most agreed-upon answer from annotators. Itâ€™s simple but ignores multiple valid answers.</li><li><strong>Multi-Label Regression</strong>: The model predicts scores for multiple candidate answers, reflecting how many annotators agreed (e.g., VQA-v1 uses a soft score like <code>min(# humans agreeing / 3, 1)</code>). This handles multiple correct answers better. The BUTD model pioneered this by treating it as a regression task, and most modern models follow this approach.</li></ul></li><li><strong>Pros</strong>: Easy to implement and evaluate.</li><li><strong>Cons</strong>: Canâ€™t predict new answers not seen in training.</li></ul></li><li><p><strong>Generative Approach</strong>:</p><ul><li>Uses an RNN to generate answers word by word.</li><li><strong>Issue</strong>: Hard to evaluate, so itâ€™s rarely used.</li></ul></li></ol><p>For <strong>Multiple-Choice VQA</strong>:</p><ul><li>Treated as a ranking problem: The model scores each question-image-answer trio, and the highest-scoring answer wins.</li></ul><p><strong>Answer Representation</strong>:</p><ul><li>Most models use <strong>one-hot vectors</strong> (e.g., [1, 0, 0] for &quot;dog&quot;) for answers, which is simple but loses semantic meaningâ€”e.g., &quot;cat&quot; and &quot;German Shepherd&quot; are equally wrong compared to &quot;dog.&quot;</li><li>Some newer approaches embed answers into the same semantic space as questions (like word vectors), turning answering into a regression of answer vectors. This makes &quot;German Shepherd&quot; closer to &quot;dog&quot; than &quot;cat,&quot; improving the modelâ€™s understanding and training signal.</li></ul><p>In short, modern VQA answering leans toward multi-label regression for open-ended questions, using soft scores from annotators, while multiple-choice uses ranking. Efforts are ongoing to make answer representations more semantically rich!</p><h3 id="mutilmodel-fusion" tabindex="-1"><a class="header-anchor" href="#mutilmodel-fusion"><span>Mutilmodel Fusion</span></a></h3><p>In order to perform joint reasoning on a QA pair, information from the two modalities have to mix and interact. This can be achieved by multimodal fusion. We divide fusion in VQA into two types, <strong>vector operation</strong> and <strong>bilinear pooling</strong>.</p><h4 id="vector-operation" tabindex="-1"><a class="header-anchor" href="#vector-operation"><span>Vector operation</span></a></h4><p>In vector addition and multiplication, question and image features are projected linearly through fully-connected layers to match their dimensions.</p><blockquote><p>Namely: fusion the vector of image and question by vector operation</p></blockquote><ul><li>cons: Bad Accuarcy</li></ul><h4 id="bilinear-pooling" tabindex="-1"><a class="header-anchor" href="#bilinear-pooling"><span>Bilinear pooling</span></a></h4><blockquote><p>The following content is generated by Grok3 for the raw survey is too hard for me. à²¥_à²¥</p></blockquote><p><strong>Bilinear Pooling</strong> combines question and image feature vectors (e.g., both 2048-dimensional) by computing their <strong>outer product</strong>, capturing all interactions between them. For an output ( &lt;z_i ) (answer score), itâ€™s defined as ( z_i = x^T W_i y ), where ( x ) is the question vector, ( y ) is the image vector, and ( W ) is a huge weight tensor. However, with 3000 answer classes, this requires billions of parameters (e.g., 12.5 billion), making it computationally expensive and prone to overfitting. Different models tweak this to balance complexity and performance:</p><blockquote><ol><li><p><strong>MCB (Multimodal Compact Bilinear)</strong>:</p><ul><li>Uses a trick from math: the outer productâ€™s &quot;count sketch&quot; can be computed as a convolution of individual sketches.</li><li>Replaces convolution with an efficient element-wise product in FFT space to indirectly get the outer product.</li><li>Still has many parameters due to fixed random settings.</li></ul></li><li><p><strong>MLB (Multimodal Low-rank Bilinear)</strong>:</p><ul><li>Reduces parameters by decomposing ( W = U V^T ), turning ( z_i = 1^T (U_i^T x \circ V_i^T y) ) (where ( \circ ) is element-wise multiplication).</li><li>Limits ( W )â€™s rank to ( k ), cutting complexity, and adds a matrix ( P_i ) for further reduction.</li><li>Downside: Slow to train and sensitive to tuning.</li></ul></li><li><p><strong>MFB (Multimodal Factorized Bilinear)</strong>:</p><ul><li>Tweaks MLB by adjusting ( U ) and ( V ) dimensions and adding <strong>sum pooling</strong> over windows of size ( k ): ( z = SumPool(U&#39;^T x \circ V&#39;^T y, k) ).</li><li>MLB is a special case when ( k = 1 ). <strong>MFH</strong> stacks MFBs for richer pooling.</li></ul></li><li><p><strong>MUTAN (Multimodal Tucker Fusion)</strong>:</p><ul><li>Uses <strong>Tucker decomposition</strong>: ( W = \tau_c \times W_q \times W_v \times W_o ).</li><li>( W_q ) and ( W_v ) project question and image vectors, ( \tau_c ) controls interaction complexity, and ( W_o ) scores answers.</li><li>MCB and MLB are simpler versions of this.</li></ul></li><li><p><strong>BLOCK</strong>:</p><ul><li>Uses <strong>block-term decomposition</strong>, balancing MLB (many small blocks, high-dimensional but weak interactions) and MUTAN (one big block, strong interactions but less accurate projections).</li><li>Strikes a middle ground and often performs better.</li></ul></li></ol></blockquote><p>In short, bilinear pooling fuses question and image data via their outer product, but raw computation is impractical. These models (MCB, MLB, MFB, MUTAN, BLOCK) reduce parameters in clever ways, trading off expressiveness (how much they capture) and trainability (how easy they are to optimize). Each improves on the last, with BLOCK aiming for the best of both worlds!</p><h3 id="attention" tabindex="-1"><a class="header-anchor" href="#attention"><span>Attention</span></a></h3><p>Make the model to focus on the object that are more relavant to <strong>questions</strong> to filter out noise and imrove accuarcy.</p><h4 id="soft-and-hard-attention" tabindex="-1"><a class="header-anchor" href="#soft-and-hard-attention"><span>Soft and hard attention</span></a></h4><p>Both of <strong>soft attention</strong> and <strong>hard attention</strong> use the question to make a map, which assigns the objects on the picture to different values--the more relavent, the higher the value is.</p><p>But the difference lies in:</p><ul><li><strong>Soft attention</strong> assigns all the object to a cretain value, do not dismiss any objects;</li><li><strong>Hard attention</strong> discard those with low relavance, and only cares about those relavent to the questions</li></ul><h4 id="grid-and-objct-based-attention" tabindex="-1"><a class="header-anchor" href="#grid-and-objct-based-attention"><span>Grid and objct based attention</span></a></h4><h4 id="bottom-up-and-top-down-attention" tabindex="-1"><a class="header-anchor" href="#bottom-up-and-top-down-attention"><span>BOTTOM-UP AND TOP-DOWN ATTENTION</span></a></h4><h4 id="co-attention-and-self-attention" tabindex="-1"><a class="header-anchor" href="#co-attention-and-self-attention"><span>CO-ATTENTION AND SELF-ATTENTION</span></a></h4><blockquote><p>To get more about these attention machenism, read the raw paper.</p></blockquote><h3 id="external-knowledge" tabindex="-1"><a class="header-anchor" href="#external-knowledge"><span>External Knowledge</span></a></h3><p>Sometimes the model need more information to solve the problem,int that case, we need to give the model the capability to query an <strong>External Knowledge Base</strong> or <strong>EKB</strong>.</p><hr><h1 id="ä¾‹ä¼šæ±‡æŠ¥-ç¬¬ä¸€æ¬¡" tabindex="-1"><a class="header-anchor" href="#ä¾‹ä¼šæ±‡æŠ¥-ç¬¬ä¸€æ¬¡"><span>ä¾‹ä¼šæ±‡æŠ¥ | ç¬¬ä¸€æ¬¡</span></a></h1><h2 id="vqaç®—æ³•" tabindex="-1"><a class="header-anchor" href="#vqaç®—æ³•"><span><strong>VQAç®—æ³•</strong></span></a></h2><div class="language-mermaid line-numbers-mode" data-highlighter="shiki" data-ext="mermaid" data-title="mermaid" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">graph LR</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">	å›¾åƒ,é—®é¢˜å±•ç¤º  --&gt; å°†æ–‡å­—,å›¾åƒç‰¹å¾ç»¼åˆ --&gt; å›ç­”ç”Ÿæˆ</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol><li><strong>å›¾åƒ/é—®é¢˜è¡¨å¾æ–¹æ³•</strong></li></ol><ul><li>å›¾åƒå±•ç¤º | Image representation</li><li>é—®é¢˜å‘ˆç° | Question representation</li></ul><ol start="2"><li><strong>å¤šæ¨¡æ€èåˆä¸å›ç­”ç”Ÿæˆç®—æ³•</strong></li></ol><ul><li>å°†è§†è§‰ä¿¡æ¯å’Œæ–‡å­—ä¿¡æ¯ç»¼åˆ | Fusion and/or Attention</li></ul><blockquote><p>The interaction of the visual and textual domain in VQA is either done directly through multimodal fusion or indirectly through attention mechanisms. --- <em>A Comprehensive Survey on Visual Question Answering Datasets and Algorithms</em></p></blockquote><ul><li>é—®é¢˜ç”Ÿæˆ | Answering</li></ul><h3 id="å¤šæ¨¡æ€èåˆ" tabindex="-1"><a class="header-anchor" href="#å¤šæ¨¡æ€èåˆ"><span>å¤šæ¨¡æ€èåˆ</span></a></h3><p>â€œå°†ä¸åŒæ¨¡æ€çš„ä¿¡æ¯ï¼Œå½¢æˆä¸€ä¸ªè”åˆçš„è¡¨ç¤ºâ€</p><blockquote><p>We divide fusion in VQA into two types, vector operation and bilinear pooling.</p><pre><code>--- *A Comprehensive Survey on Visual Question Answering Datasets and Algorithms*
</code></pre></blockquote><h5 id="åŸºäºå‘é‡æ“ä½œçš„èåˆ" tabindex="-1"><a class="header-anchor" href="#åŸºäºå‘é‡æ“ä½œçš„èåˆ"><span>åŸºäºå‘é‡æ“ä½œçš„èåˆ</span></a></h5><ol><li>å‘é‡æ“ä½œ | Vector Operation</li></ol><p>â€‹ é€šè¿‡å‘é‡æ“ä½œï¼ˆåŠ æ³•ï¼Œå†…ç§¯ï¼Œæ‹¼æ¥ï¼‰ï¼Œå°†å›¾åƒç‰¹å¾å’Œé—®é¢˜ç‰¹å¾ç»“åˆèµ·æ¥ï¼Œç”Ÿæˆä¸€ä¸ªè”åˆçš„å¤šæ¨¡æ€è¡¨ç¤ºã€‚</p><ul><li>å®¹æ˜“å®ç°</li><li>å‡†ç¡®åº¦ä½</li></ul><ol start="2"><li>åŒçº¿æ€§æ± åŒ–å±‚ | Bilinear pooling</li></ol><p>â€‹ é€šè¿‡å°†ä»£è¡¨ è§†è§‰ä¿¡æ¯ å’Œ æ–‡å­—ä¿¡æ¯ çš„ <strong>å‘é‡åšå¤–ç§¯</strong>ï¼Œâ€œæ¯”ç®€å•çš„å‘é‡æ“ä½œï¼ˆå¦‚åŠ æ³•ã€ä¹˜æ³•æˆ–æ‹¼æ¥ï¼‰æ›´æœ‰æ•ˆåœ°æ•æ‰æ¨¡æ€é—´çš„ç›¸å…³æ€§ã€‚â€</p><hr><h5 id="æ³¨æ„åŠ›æœºåˆ¶-attention" tabindex="-1"><a class="header-anchor" href="#æ³¨æ„åŠ›æœºåˆ¶-attention"><span>æ³¨æ„åŠ›æœºåˆ¶ | Attention</span></a></h5><p>ç”¨äºè®©æ¨¡å‹<strong>èšç„¦</strong>è¾“å…¥æ•°æ®ä¸­çš„é‡è¦éƒ¨åˆ†ï¼Œå‡å°‘å™ªéŸ³çš„å¹²æ‰°</p><ul><li>æ³¨æ„åŠ›æœºåˆ¶å¯ä»¥å¸®åŠ©æ¨¡å‹åŠ¨æ€åœ°é€‰æ‹©å›¾åƒå’Œæ–‡æœ¬ä¸­çš„é‡è¦åŒºåŸŸæˆ–è¯æ±‡</li></ul><p>æ³¨æ„åŠ›æœºåˆ¶æœ‰å¾ˆå¤šç§åˆ†ç±»æ–¹å¼ï¼š</p><p>æ¯”å¦‚ï¼šSoft and hard attention</p><p>æŒ‰ç…§ä¸é—®é¢˜çš„ç›¸å…³ç¨‹åº¦ï¼Œç»™å›¾åƒä¸­çš„å¯¹è±¡èµ‹å€¼ã€‚</p><p>åŒºåˆ«åœ¨äº<strong>soft attention</strong>æœºåˆ¶ä¸ä¼šå°†ç›¸å…³åº¦ä½çš„å¯¹è±¡ç»™å¿½è§†ï¼Œè€Œ<strong>hard attention</strong>åˆ™ä¼šèˆå¼ƒç›¸å…³åº¦ä½çš„å¯¹è±¡</p><p>å…¶ä»–çš„æ³¨æ„åŠ›æœºåˆ¶æœ‰</p><ul><li><p>Grid and objct based attention</p></li><li><p>bottom-up and top-down attention</p></li><li><p>single setp and s multi-step attention</p></li><li><p>CO-ATTENTION AND SELF-ATTENTION</p></li></ul><hr><p>ä¸Šé¢çš„å†…å®¹ç›¸å½“äºæ˜¯è®©æ¨¡å‹â€œç†è§£â€äº†é—®é¢˜å’Œå›¾åƒï¼Œä¸‹é¢éœ€è¦ç”Ÿæˆå›ç­”ï¼š</p><h3 id="å›ç­”ç”Ÿæˆç®—æ³•" tabindex="-1"><a class="header-anchor" href="#å›ç­”ç”Ÿæˆç®—æ³•"><span>å›ç­”ç”Ÿæˆç®—æ³•</span></a></h3><ul><li><p><strong>åˆ†ç±»é—®é¢˜ | close ending</strong> ï¼š</p><p>å°†å‰é¢å¤šæ¨¡æ€èåˆå¾—åˆ°çš„ç‰¹å¾è¾“å…¥åˆ°<code>å…¨è¿æ¥å±‚</code>ï¼Œæœ€åé€šè¿‡<code>softmax</code>å‡½æ•°å¾—åˆ°ç­”æ¡ˆçš„æ¦‚ç‡åˆ†å¸ƒï¼›</p><p>(æˆ‘è§‰å¾—å’Œæ‰‹å†™æ•°å­—è¯†åˆ«ç±»ä¼¼)</p><p>â€‹</p></li><li><p><strong>è‡ªç”±ç”Ÿæˆ | open ending</strong>ï¼š</p><p>ç”Ÿæˆè‡ªç”±çš„æ–‡æœ¬ï¼ˆå’Œå¹³æ—¶çš„å¤§è¯­è¨€æ¨¡å‹äº¤äº’æ‰€ç”Ÿæˆçš„å›ç­”ä¸€æ ·ï¼‰;</p><p><code>ç¼–ç å™¨-é˜¶ç å™¨</code>ç»“æ„ï¼š</p><ul><li>ç¼–ç å™¨æå–å›¾åƒå’Œé—®é¢˜çš„è”åˆè¡¨ç¤º</li><li>è§£ç å™¨æŒ‰ç…§ç¼–ç å™¨è¾“å‡ºï¼Œé€è¯ç”Ÿæˆç­”æ¡ˆ</li></ul></li></ul><p>åœ¨å›ç­”ç”Ÿæˆç®—æ³•ä¸­ï¼ŒTransformeræ¨¡å‹æ¯”è¾ƒæµè¡Œ:</p><p><strong>Transformeræ¨¡å‹</strong></p><ul><li><p><strong>æå–æ–‡æœ¬ã€å›¾åƒä¿¡æ¯ï¼Œå¹¶èåˆ</strong>ï¼š</p><ul><li>Two-Stream å›¾åƒå’Œæ–‡æœ¬åˆ†åˆ«é€šè¿‡ç‹¬ç«‹çš„ Transformer ç¼–ç å™¨å¤„ç†ï¼Œæœ€åå†å°†ä¸¤ä¸ªè¾“å‡ºèåˆã€‚ä¾‹å­ï¼šViLBERT, LXMERT, and ERNIE-ViL</li></ul><blockquote><p>In the two-stream architecture, two seperate transformers are applied to image and text and their outputs are fused by a third Transformer in a later stage.</p></blockquote><ul><li>Single-Stream: å°†å›¾åƒå’Œæ–‡æœ¬è§†ä¸ºä¸€ä¸ªç»Ÿä¸€çš„åºåˆ—ï¼Œé€šè¿‡åŒä¸€ä¸ª Transformer ç¼–ç å™¨å¤„ç†ã€‚ä¾‹å­ï¼šViLTã€OFAã€M6ã€VisualBERT</li></ul><blockquote><p>In contrast, single-stream models use a single transformer for joint intra-modal and inter-modal interaction.</p></blockquote></li><li><p><strong>å›ç­”ç”Ÿæˆ</strong>:</p><ul><li><p><strong>åˆ†ç±»é—®é¢˜ | close ending</strong>ï¼š</p><p>åœ¨ Transformer ç¼–ç å™¨çš„è¾“å‡ºåæ·»åŠ åˆ†ç±»å¤´ï¼ˆClassification Headï¼‰ã€‚</p><p>é€šè¿‡å…¨è¿æ¥å±‚å°†èåˆåçš„ç‰¹å¾æ˜ å°„åˆ°ç­”æ¡ˆè¯æ±‡è¡¨çš„åˆ†å¸ƒã€‚</p></li><li><p><strong>è‡ªç”±ç”Ÿæˆ | open ending</strong>ï¼š</p><p>ä½¿ç”¨ Transformer çš„ <strong>ç¼–ç å™¨-è§£ç å™¨æ¶æ„</strong> ï¼Œç¼–ç å™¨å¾—åˆ°è§†è§‰å’Œæ–‡å­—ç‰¹å¾çš„ç‰¹å¾åºåˆ—ï¼Œè¾“å…¥åˆ°è§£ç å™¨ç”Ÿæˆç­”æ¡ˆã€‚</p></li></ul></li></ul><hr><p>ç»¼è¿°ä¸­æåˆ°çš„å…¶ä»–ç›¸å…³å†…å®¹ï¼š</p><h5 id="å¤–éƒ¨çŸ¥è¯†-external-knowledge" tabindex="-1"><a class="header-anchor" href="#å¤–éƒ¨çŸ¥è¯†-external-knowledge"><span>å¤–éƒ¨çŸ¥è¯† | EXTERNAL KNOWLEDGE</span></a></h5><p>å¤–éƒ¨çŸ¥è¯†æ˜¯æŒ‡ä»é¢„å®šä¹‰çš„çŸ¥è¯†åº“ï¼ˆå¦‚çŸ¥è¯†å›¾è°±ã€æ•°æ®åº“ï¼‰æˆ–é¢„è®­ç»ƒæ¨¡å‹ä¸­å¼•å…¥çš„é¢å¤–çŸ¥è¯†</p><ul><li>å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°å›ç­”é—®é¢˜</li></ul><h5 id="ç»„åˆå¼æ¨ç†-compositional-reasoning" tabindex="-1"><a class="header-anchor" href="#ç»„åˆå¼æ¨ç†-compositional-reasoning"><span>ç»„åˆå¼æ¨ç† | Compositional reasoning</span></a></h5><p>å°†é—®é¢˜æ‹†åˆ†æˆå¤šä¸ªå­é—®é¢˜ï¼Œæ¥æ­£ç¡®åœ°æ¨ç†å¤æ‚é—®é¢˜</p><blockquote><p>By composition, we refer to the ability to break a question down into individual reasoning steps which when done sequentially produces the correct answer. â€œç»„åˆ&quot;æŒ‡çš„æ˜¯å°†é—®é¢˜æ‹†åˆ†æˆå­é—®é¢˜çš„èƒ½åŠ›</p></blockquote><h3 id="å°è¯•" tabindex="-1"><a class="header-anchor" href="#å°è¯•"><span>å°è¯•</span></a></h3><p>åœ¨äº†è§£ç›¸å…³æ¨¡å‹çš„æ—¶å€™ï¼Œæˆ‘äº†è§£åˆ°ä¸€ä¸ªåŸºäºtransformerçš„æ¨¡å‹æ¡†æ¶BLIP(2022å¹´æå‡º)ã€‚</p><p>BLIPè®­ç»ƒéš¾(æ•°æ®ï¼Œç®—åŠ›)</p><ul><li><p><a href="https://huggingface.co/docs/transformers/main/en/model_doc/blip#blip" target="_blank" rel="noopener noreferrer">HuggingFaceæ–‡æ¡£-é“¾æ¥</a></p></li><li><p><a href="https://github.com/salesforce/BLIP" target="_blank" rel="noopener noreferrer">è®­ç»ƒä»£ç Giuhub-é“¾æ¥</a></p></li></ul><hr><p>hugging faceä¸Šé¢æœ‰å‡ ä¸ªåŸºäºè¿™ä¸ªæ¡†æ¶çš„æ¨¡å‹ï¼Œæˆ‘ä¸‹è½½äº†å‡ ä¸ªæƒ³çœ‹çœ‹æ•ˆæœæ˜¯ä»€ä¹ˆæ ·çš„ï¼Œå†™äº†ä¸€ä¸ªå¯¹è¯çš„æœ¬åœ°ç½‘é¡µï¼š</p><div style="display:grid;grid-template-columns:1fr 1fr;"><img src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250313172815938.png"><img src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250313173022433.png"></div> &gt; ~~**æˆ‘ä»¬åˆ°æ—¶å€™æ˜¯ä¸æ˜¯ä¹Ÿå¯ä»¥å°†æœ€ç»ˆçš„æ¨¡å‹åšä¸€ä¸ªç½‘é¡µçš„demo**~~ <h3 id="æœ‰å…³vqaå­¦ä¹ çš„ç–‘æƒ‘" tabindex="-1"><a class="header-anchor" href="#æœ‰å…³vqaå­¦ä¹ çš„ç–‘æƒ‘"><span>æœ‰å…³VQAå­¦ä¹ çš„ç–‘æƒ‘</span></a></h3><ol><li>å­¦ä¹ æ—¶é—´æœ‰é™ï¼Œé™¤éæ”¾å‡å¾ˆéš¾æœ‰<strong>è¶³å¤Ÿå¤š</strong>çš„æ—¶é—´æ¥ç³»ç»Ÿå­¦ä¹ ï¼Œå­¦ä¹ è¿›åº¦ç¼“æ…¢ã€‚</li><li>ä»å“ªé‡Œå¼€å§‹ä¸‹æ‰‹ï¼Ÿéœ€è¦å…ˆç³»ç»Ÿå­¦ä¹ pytorchï¼Œtransformerç­‰å—ï¼Ÿ</li></ol><blockquote><p>python-&gt;pytorch-&gt;çœ‹ä¸€äº›ç›¸å…³å®ç°å’Œç®—æ³•</p></blockquote><hr><h1 id="ä¾‹ä¼šæ±‡æŠ¥-ç¬¬äºŒæ¬¡" tabindex="-1"><a class="header-anchor" href="#ä¾‹ä¼šæ±‡æŠ¥-ç¬¬äºŒæ¬¡"><span>ä¾‹ä¼šæ±‡æŠ¥ | ç¬¬äºŒæ¬¡</span></a></h1><p>ï¼ˆæ¥ä¸Šä¸€æ¬¡BLIPç³»åˆ—æ¨¡å‹çš„è®¨è®ºï¼‰æˆ‘æ²¡æœ‰ä»”ç»†çœ‹å¯¹åº”çš„è®ºæ–‡ï¼Œä¸‹æ–¹å›¾ç‰‡æ¥è‡ªçŸ¥ä¹ã€‚</p><figure><img src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/6fb85be2a08f15ce71245f1301d3b1ab.png" alt="6fb85be2a08f15ce71245f1301d3b1ab" tabindex="0" loading="lazy"><figcaption>6fb85be2a08f15ce71245f1301d3b1ab</figcaption></figure><hr><h4 id="ä¸€ä¸ªvqaé¢†åŸŸçš„baselineæ¨¡å‹" tabindex="-1"><a class="header-anchor" href="#ä¸€ä¸ªvqaé¢†åŸŸçš„baselineæ¨¡å‹"><span>ä¸€ä¸ªVQAé¢†åŸŸçš„baselineæ¨¡å‹</span></a></h4><blockquote><p>Baselineæ¨¡å‹çš„å«ä¹‰ï¼š å®¹æ˜“å®ç°ã€åŠŸèƒ½åŸºç¡€çš„æ¨¡å‹ï¼Œä½œä¸º&#39;åŸºçº¿&#39;(baseline)ã€‚</p></blockquote><p>æˆ‘æ‰¾åˆ°ä¸€ç¯‡10å¹´å‰çš„è®ºæ–‡ï¼š<a href="paper.html">Simple Baseline for Visual Question Answering</a>ï¼Œæ–‡ç« ä¸­æåˆ°çš„â€œiBowingâ€æ¨¡å‹çš„ç»“æ„æ˜¯ï¼š</p><div class="language-mermaid line-numbers-mode" data-highlighter="shiki" data-ext="mermaid" data-title="mermaid" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">graph TD</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    A[è¾“å…¥é—®é¢˜ï¼ˆæ–‡æœ¬ï¼‰] --&gt;|One-hot Encoding + è¯è¢‹æ¨¡å‹ï¼ˆBoWï¼‰| B[æ–‡æœ¬ç‰¹å¾]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    C[è¾“å…¥å›¾åƒ] --&gt;|CNNï¼ˆå¦‚GoogLeNetï¼‰| D[å›¾åƒç‰¹å¾]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    B --&gt;|æ‹¼æ¥| E[è”åˆç‰¹å¾å‘é‡]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    D --&gt;|æ‹¼æ¥| E</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    E --&gt;|Softmax åˆ†ç±»| F[é¢„æµ‹ç­”æ¡ˆ]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>æ¨¡å‹æ ¸å¿ƒæ€è·¯å¦‚ä¸‹ï¼š</p><ol><li><p><strong>æ–‡å­—å¤„ç†</strong></p><ul><li><strong>One-hot Encoding ä¸ Bag-of-Words (BoW)ï¼š</strong><br> æ¨¡å‹é¦–å…ˆå°†è¾“å…¥çš„é—®å¥è½¬æ¢ä¸º one-hot å‘é‡ã€‚åœ¨ one-hot encoding ä¸­ï¼Œæ¯ä¸ªå•è¯éƒ½è¡¨ç¤ºä¸ºä¸€ä¸ªäºŒå€¼å‘é‡ï¼ˆåªæœ‰å¯¹åº”å•è¯çš„ä½ç½®ä¸º 1ï¼Œå…¶ä½™ä½ç½®ä¸º 0ï¼‰ã€‚è¿™ç§æ–¹æ³•æ­£æ˜¯å®ç°äº†æ‰€è°“çš„â€œè¯è¢‹æ¨¡å‹â€ï¼ˆBag-of-Wordsï¼‰ï¼Œè¯¥æ¨¡å‹åªå…³æ³¨è¯æ±‡çš„å‡ºç°é¢‘ç‡è€Œå¿½ç•¥è¯åºã€‚</li></ul><blockquote><p>Bowï¼ˆè¯è¢‹æ¨¡å‹ï¼‰æ˜¯åªç»Ÿè®¡å•è¯åœ¨è¯æ±‡è¡¨ä¸­çš„å‡ºç°æƒ…å†µï¼Œå¿½ç•¥äº†å•è¯çš„è¯­ä¹‰å…³ç³»å’Œæ¬¡åºå…³ç³»ã€‚</p><p><strong>ä½†æ˜¯</strong>ï¼Œè¿™ä¸ªæ¨¡å‹å¹¶æ²¡æœ‰ç›´æ¥ä½¿ç”¨one-hotå‘é‡ï¼Œè€Œæ˜¯é€šå…¥ä¸€ä¸ªåµŒå…¥å±‚ï¼Œå®ç°è¯åµŒå…¥: The input question is first converted to a one-hot vector, which is transformed to word feature via a word embedding layer</p></blockquote><ul><li><strong>Word Embeddingï¼ˆè¯åµŒå…¥ï¼‰ï¼š</strong><br> å°† one-hot å‘é‡è¾“å…¥åˆ°è¯åµŒå…¥å±‚ä¸­ï¼Œè½¬æ¢ä¸ºä½ç»´ç¨ å¯†å‘é‡ã€‚è¯åµŒå…¥èƒ½å¤Ÿæ•æ‰å•è¯ä¹‹é—´çš„è¯­ä¹‰å…³ç³»ï¼Œæ¯”ç®€å•çš„é¢‘æ•°ç»Ÿè®¡æä¾›äº†æ›´ä¸°å¯Œçš„è¯­ä¹‰ä¿¡æ¯ã€‚</li></ul></li><li><p><strong>å›¾åƒå¤„ç†</strong></p><ul><li>åˆ©ç”¨é¢„è®­ç»ƒ CNNï¼ˆä¾‹å¦‚ GoogLeNetï¼‰æå–å›¾åƒæ·±åº¦ç‰¹å¾ï¼Œè·å¾—å›¾åƒçš„é«˜å±‚è¯­ä¹‰ä¿¡æ¯ã€‚</li></ul></li><li><p><strong>ç‰¹å¾æ‹¼æ¥ï¼ˆConcatenationï¼‰ï¼š</strong><br> å°†æ–‡å­—ç‰¹å¾å’Œå›¾åƒç‰¹å¾ç›´æ¥è¿›è¡Œæ‹¼æ¥ï¼Œå³å°†ä¸¤ä¸ªå‘é‡<strong>æ¨ªå‘è¿æ¥</strong>ï¼Œå½¢æˆä¸€ä¸ªè”åˆç‰¹å¾å‘é‡ã€‚è¿™ç§æ‹¼æ¥æ–¹å¼èƒ½å¤ŸåŒæ—¶åŒ…å«é—®é¢˜çš„æ–‡æœ¬ä¿¡æ¯å’Œå›¾åƒçš„è§†è§‰ä¿¡æ¯ï¼Œä¸ºåç»­çš„åˆ†ç±»æä¾›å…¨é¢çš„è¾“å…¥ç‰¹å¾ã€‚</p><blockquote><p>è¿™é‡Œçš„<strong>æ‹¼æ¥</strong>æ˜¯è¿™ä¸ªå«ä¹‰ï¼š</p><ul><li><strong>æ–‡æœ¬ç‰¹å¾å‘é‡</strong>ï¼š<code>T = [0.2, 0.5, 0.3]</code> ï¼ˆå‡è®¾ 3 ç»´å‘é‡ï¼‰</li><li><strong>å›¾åƒç‰¹å¾å‘é‡</strong>ï¼š<code>I = [0.7, 0.1, 0.9, 0.4]</code> ï¼ˆå‡è®¾ 4 ç»´ç‰¹å¾ï¼‰</li></ul><p>é‚£ä¹ˆï¼Œæ‹¼æ¥åçš„ <strong>è”åˆç‰¹å¾å‘é‡</strong> <code>F</code> å°±æ˜¯ï¼šF=[0.2,0.5,0.3,0.7,0.1,0.9,0.4]</p></blockquote><!----><figure><img src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/x1.png" alt="Refer to caption" tabindex="0" loading="lazy"><figcaption>Refer to caption</figcaption></figure></li><li><p><strong>ç­”æ¡ˆç”Ÿæˆ</strong></p><p>ä½¿ç”¨Softmax åˆ†ç±»å™¨ï¼š<br> å°†æ‹¼æ¥åçš„è”åˆç‰¹å¾è¾“å…¥åˆ°ä¸€ä¸ª softmax å±‚ï¼Œè¯¥å±‚ä½œä¸ºå¤šç±»åˆ«åˆ†ç±»å™¨ï¼Œè®¡ç®—æ¯ä¸ªé¢„å®šä¹‰ç­”æ¡ˆç±»åˆ«çš„æ¦‚ç‡åˆ†å¸ƒã€‚æœ€ç»ˆï¼Œé€‰æ‹©å…·æœ‰æœ€é«˜æ¦‚ç‡çš„ç­”æ¡ˆä½œä¸ºæ¨¡å‹çš„è¾“å‡ºã€‚</p></li></ol><figure><img src="https://pica.zhimg.com/v2-4452fdaaa04686aa270010f57f4db2aa_1440w.jpg" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>softmaxæœ€ç»ˆå¾—åˆ°ä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒçš„å¼ é‡ï¼Œå¯¹åº”çš„æ¦‚ç‡ä»£è¡¨ç­”æ¡ˆæ˜¯å¯¹åº”çš„è¯çš„æ¦‚ç‡</p><blockquote><p>Softmax <strong>åªèƒ½ä»ä¸€ä¸ªå›ºå®šçš„å€™é€‰é›†åˆä¸­é€‰ç­”æ¡ˆ</strong>ã€‚è¿™ä¸ªé›†åˆé€šå¸¸æ˜¯ <strong>è®­ç»ƒæ•°æ®ä¸­å­¦ä¹ åˆ°çš„å¯èƒ½ç­”æ¡ˆé›†åˆ</strong>ï¼Œä¹Ÿå°±æ˜¯ <strong>é¢„å®šä¹‰çš„è¯è¡¨ï¼ˆVocabularyï¼‰</strong>ã€‚ä¹Ÿå°±æ˜¯è¯´æ— æ³•ç”Ÿæˆè‡ªç”±çš„å›ç­”ã€‚</p></blockquote><p>githubï¼š<a href="https://github.com/zhoubolei/VQAbaseline" target="_blank" rel="noopener noreferrer">zhoubolei/VQAbaseline: Simple Baseline for Visual Question Answering</a>(ä½†æ˜¯ä¸æ˜¯ç”¨pythonå†™çš„ï¼Œè€Œæ˜¯luaï¼Œåœ¨çº¿çš„demoä¹Ÿå·²ç»åœæ­¢è¿è¡Œ)</p><hr><p><strong>è®­ç»ƒçš„ç»†èŠ‚å’Œç»“æœ</strong></p><p>è®ºæ–‡ä¸­ä½¿ç”¨åˆ°çš„æ•°æ®é›†æ˜¯<code>COCOæ•°æ®é›†</code>ï¼Œè®ºæ–‡ä¸­æåˆ°è®­ç»ƒçš„ç»†èŠ‚ï¼š<code>åœ¨å•ä¸ª NVIDIA Titan Black GPU ä¸Šè®­ç»ƒå¤§çº¦éœ€è¦ 10 å°æ—¶</code></p><blockquote><p>åŸæ–‡ï¼šThe training takes about 10 hours on a single GPU NVIDIA Titan Black</p></blockquote><figure><img src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250322203830571.png" alt="image-20250322203830571" tabindex="0" loading="lazy"><figcaption>image-20250322203830571</figcaption></figure><p>è¿™ä¸ªæ˜¯é˜¿é‡Œäº‘ä¸ŠGPUçš„ä»·æ ¼ã€‚</p><figure><img src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250322204019083.png" alt="image-20250322204019083" tabindex="0" loading="lazy"><figcaption>image-20250322204019083</figcaption></figure><p>ä¹Ÿå°±æ˜¯è¯´ï¼ŒæŒ‰ç…§è¿™ç¯‡è®ºæ–‡æ‰€è¯´ï¼Œè®­ç»ƒè¿™ä¸ªæ¨¡å‹ï¼Œå¯èƒ½èŠ±è´¹30rä¸åˆ°ã€‚</p><p>ä¸‹é¢æ˜¯è®ºæ–‡ä¸­æåˆ°çš„æµ‹è¯•çš„ç»“æœï¼š</p><div style="display:flex;"><img width="50%" src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250322205621368.png"><img width="50%" style="height:100%;" src="https://yamapicgo.oss-cn-nanjing.aliyuncs.com/picgoImage/image-20250322205703229.png"></div> --- <p>è€å¸ˆæ³¨ï¼š æ•°æ®é‡è¦æ€§å¤§äºç®—åŠ›ï¼Œæ˜¾å­˜è¦æ±‚å¤§äºcudaæ ¸ï¼Œè®­ç»ƒæ»¡ä¸€ç‚¹æ²¡å…³ç³»ã€‚</p><p>è®ºæ–‡é‡Œå¯¹æ¨¡å‹çš„åˆ†æï¼Œè¦å’Œå…¶ä»–çš„æ¨¡å‹è¿›è¡Œå¯¹æ¯”ï¼Œè¿˜è¦è¿›è¡Œ<strong>å‰–åˆ†å®éªŒ</strong> ï¼ˆwithoutè¿™ä¸ªæ¨¡å—ï¼Œä¹‹åæ€§èƒ½æ€ä¹ˆæ ·ï¼Ÿ æŠŠè¿™ä¸ªcomponentæ¢æˆåˆ«çš„æ€§èƒ½æ€ä¹ˆæ ·ï¼‰ï¼Œæ•æ„Ÿåº¦ï¼Œæ¨¡å‹æ€§èƒ½éšç€å‚æ•°çš„å˜åŒ–çš„å˜åŒ–è¶‹åŠ¿</p><p>å‰é¢æåˆ°çš„é‚£ä¸ªbaselineæ¨¡å‹ä½¿ç”¨ç®€å•çš„<code>ç‰¹å¾æå–-&gt; ç‰¹å¾èåˆ -&gt; softmaxå¾—åˆ°ç­”æ¡ˆ</code>ã€‚</p><p>å…·ä½“çš„æ¥è¯´ï¼ŒiBowingæ¨¡å‹åœ¨æ–‡å­—ç¼–ç æ—¶é‡‡ç”¨çš„æ˜¯<strong>Bow</strong>(è¯è¢‹æ¨¡å‹). æ¯”è¯è¢‹æ¨¡å‹ç”¨çš„æ›´å¹¿æ³›çš„æ˜¯ï¼š<strong>RNN</strong>(å¾ªç¯ç¥ç»ç½‘ç»œ)ã€‚ä¸‹é¢å±•ç¤ºæ˜¯ä¸€ç§æ—©æœŸå¸¸è§çš„vqaæ–¹æ³•ï¼š</p><div class="language-mermaid line-numbers-mode" data-highlighter="shiki" data-ext="mermaid" data-title="mermaid" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">graph TD</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    A[è¾“å…¥å›¾åƒ] --&gt;|CNN æå–ç‰¹å¾| B[å›¾åƒç‰¹å¾]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    A1[è¾“å…¥é—®é¢˜] --&gt;|è¯åµŒå…¥ Word2Vec/GloVe| A2[è¯å‘é‡]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    A2 --&gt;|RNN/LSTM å¤„ç†| A3[æ–‡æœ¬ç‰¹å¾]</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    B --&gt; C[æ‹¼æ¥ Concatenation]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    A3 --&gt; C</span></span>
<span class="line"></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    C --&gt;|å…¨è¿æ¥å±‚ MLP å¤„ç†| D[èåˆç‰¹å¾]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">    D --&gt;|Softmax åˆ†ç±»| E[ç­”æ¡ˆé¢„æµ‹]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>è®¸å¤švqaæ¨¡å‹éƒ½æ˜¯åŸºäºtransformerå®ç°çš„ã€‚ä¸‹å›¾æ˜¯ä¸€ä¸ªç®€å•çš„ç»“æ„ï¼ŒBLIPé‡‡å–çš„ç»“æ„å’Œè¿™ä¸ªå¾ˆç›¸ä¼¼ï¼š</p><div class="language-mermaid line-numbers-mode" data-highlighter="shiki" data-ext="mermaid" data-title="mermaid" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">graph TD</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  A[è¾“å…¥å›¾åƒ] --&gt;|ViT/CNN æå–ç‰¹å¾| B[å›¾åƒç‰¹å¾]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  C[è¾“å…¥é—®é¢˜] --&gt;|BERT/Tokenizer| D[æ–‡æœ¬ç‰¹å¾]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  B --&gt;|è·¨æ¨¡æ€èåˆ| E[å¤šæ¨¡æ€ Transformer]</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  D --&gt;|è·¨æ¨¡æ€èåˆ| E</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">  E --&gt;|Transformer Decoder| F[ç”Ÿæˆç­”æ¡ˆ]</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr></div><!----><footer class="vp-page-meta"><div class="vp-meta-item edit-link"><a class="auto-link external-link vp-meta-label" href="https://github.com/yama-lei/yama-lei.github.io/edit/main/src/posts/ç§‘ç ”å¯è’™/VQAè§†è§‰é—®ç­”ç³»ç»Ÿ.md" aria-label="åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ" rel="noopener noreferrer" target="_blank"><!--[--><svg xmlns="http://www.w3.org/2000/svg" class="icon edit-icon" viewBox="0 0 1024 1024" fill="currentColor" aria-label="edit icon" name="edit"><path d="M430.818 653.65a60.46 60.46 0 0 1-50.96-93.281l71.69-114.012 7.773-10.365L816.038 80.138A60.46 60.46 0 0 1 859.225 62a60.46 60.46 0 0 1 43.186 18.138l43.186 43.186a60.46 60.46 0 0 1 0 86.373L588.879 565.55l-8.637 8.637-117.466 68.234a60.46 60.46 0 0 1-31.958 11.229z"></path><path d="M728.802 962H252.891A190.883 190.883 0 0 1 62.008 771.98V296.934a190.883 190.883 0 0 1 190.883-192.61h267.754a60.46 60.46 0 0 1 0 120.92H252.891a69.962 69.962 0 0 0-69.098 69.099V771.98a69.962 69.962 0 0 0 69.098 69.098h475.911A69.962 69.962 0 0 0 797.9 771.98V503.363a60.46 60.46 0 1 1 120.922 0V771.98A190.883 190.883 0 0 1 728.802 962z"></path></svg><!--]-->åœ¨ GitHub ä¸Šç¼–è¾‘æ­¤é¡µ<!----></a></div><div class="vp-meta-item git-info"><div class="update-time"><span class="vp-meta-label">ä¸Šæ¬¡ç¼–è¾‘äº: </span><span class="vp-meta-info" data-allow-mismatch="text">2025/4/4 12:29:07</span></div><div class="contributors"><span class="vp-meta-label">è´¡çŒ®è€…: </span><!--[--><!--[--><span class="vp-meta-info" title="email: 1908777046@qq.com">yama-lei</span><!--]--><!--]--></div></div></footer><nav class="vp-page-nav"><a class="route-link auto-link prev" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/VQAlearning/" aria-label="VQAlearning"><div class="hint"><span class="arrow start"></span>ä¸Šä¸€é¡µ</div><div class="link"><!---->VQAlearning</div></a><a class="route-link auto-link next" href="/posts/%E7%A7%91%E7%A0%94%E5%90%AF%E8%92%99/%E4%BD%BF%E7%94%A8%E9%98%BF%E9%87%8C%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B.html" aria-label="ä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡å™¨è®­ç»ƒæ¨¡å‹"><div class="hint">ä¸‹ä¸€é¡µ<span class="arrow end"></span></div><div class="link">ä½¿ç”¨é˜¿é‡Œäº‘æœåŠ¡å™¨è®­ç»ƒæ¨¡å‹<!----></div></a></nav><!----><!----><!--]--></main><!--]--><footer class="vp-footer-wrapper" vp-footer><!----><div class="vp-copyright">Copyright Â© 2025 Yama-lei </div></footer></div><!--]--><!--[--><!----><!--[--><!--]--><!--]--><!--]--></div>
    <script type="module" src="/assets/app-CihjbUnI.js" defer></script>
  </body>
</html>
